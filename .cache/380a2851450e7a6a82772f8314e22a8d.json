{
  "full_text": "9/26/23, 7:10 PM\nUntitled0.ipynb - Colaboratory\nhttps://colab.research.google.com/drive/1sO9dZns8H-cbY8-WX6gGxybExNj-6I6n#scrollTo=N1ULFwmgqXi4&printMode=true\n1/4\nimport cv2\nimport matplotlib.pyplot as plt\n# Load the image\nimage = cv2.imread('photo1.jpeg')\n# Convert to grayscale\ngray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n# Display the grayscale image using matplotlib\nplt.imshow(gray_image, cmap='gray')\nplt.axis('off')  # Turn off axis labels\nplt.show()\nimport cv2\nimport numpy as np\n# Load the image\nimage = cv2.imread('photo1.jpeg')\n# Define the size of the blocks (sub-images)\nblock_size = 64  # Adjust this size according to your needs\n# Get the dimensions of the image\nheight, width, _ = image.shape\n# Initialize a list to store the sub-images\nsub_images = []\n# Iterate over the image in blocks\nfor y in range(0, height, block_size):\n    for x in range(0, width, block_size):\n        # Extract the sub-image (block)\n        sub_image = image[y:y+block_size, x:x+block_size]\n        sub_images.append(sub_image)\n# Display or save the sub-images\nfor i, sub_image in enumerate(sub_images):\n    cv2.imwrite(f'sub_image_{i}.jpeg', sub_image)  # Save each sub-image with a unique name\n    # To display sub-images, you can use cv2.imshow here.\n# Note: This code saves each sub-image as separate files. You can adjust it as needed.\nimport cv2\nimport numpy as np\nfrom scipy.fftpack import dct\n# Load the image and divide it into blocks (as shown in previous answers)\nimage = cv2.imread('photo1.jpeg')\nblock_size = 8\nheight, width, _ = image.shape\nsub_images = []\nfor y in range(0, height, block_size):\n\n9/26/23, 7:10 PM\nUntitled0.ipynb - Colaboratory\nhttps://colab.research.google.com/drive/1sO9dZns8H-cbY8-WX6gGxybExNj-6I6n#scrollTo=N1ULFwmgqXi4&printMode=true\n2/4\n    for x in range(0, width, block_size):\n        sub_image = image[y:y+block_size, x:x+block_size]\n        sub_images.append(sub_image)\n# Initialize a list to store DCT-transformed blocks\ndct_transformed_blocks = []\n# Perform DCT on each sub-image (block)\nfor sub_image in sub_images:\n    # Convert the sub-image to grayscale\n    gray_sub_image = cv2.cvtColor(sub_image, cv2.COLOR_BGR2GRAY)\n    # Apply DCT\n    dct_block = dct(dct(gray_sub_image, axis=0, norm='ortho'), axis=1, norm='ortho')\n    dct_transformed_blocks.append(dct_block)\n# Define the quantization step size (adjust as needed)\nquantization_step = 10\n# Initialize a list to store quantized blocks\nquantized_blocks = []\n# Perform quantization on each DCT-transformed block\nfor dct_block in dct_transformed_blocks:\n    quantized_block = np.round(dct_block / quantization_step)\n    quantized_blocks.append(quantized_block)\nimport cv2\nimport numpy as np\nfrom scipy.fftpack import idct\nimport matplotlib.pyplot as plt\n# Load the image and divide it into blocks (as shown in previous answers)\nimage = cv2.imread('photo1.jpeg')\nblock_size = 8\nheight, width, _ = image.shape\nsub_images = []\nfor y in range(0, height, block_size):\n    for x in range(0, width, block_size):\n        sub_image = image[y:y+block_size, x:x+block_size]\n        sub_images.append(sub_image)\n# Initialize a list to store the reconstructed blocks\nreconstructed_blocks = []\n# Perform inverse quantization and inverse DCT on each quantized block\nfor quantized_block in quantized_blocks:\n    # Inverse quantization\n    reconstructed_dct_block = quantized_block * quantization_step\n    # Inverse DCT\n    reconstructed_gray_sub_image = idct(idct(reconstructed_dct_block, axis=0, norm='ortho'), axis=1, norm='ortho')\n    # Create a 3-channel image (for color images)\n    reconstructed_sub_image = cv2.cvtColor(reconstructed_gray_sub_image.astype(np.uint8), cv2.COLOR_GRAY2BGR)\n    reconstructed_blocks.append(reconstructed_sub_image)\n# Reconstruct the image by arranging the blocks\nreconstructed_image = np.zeros_like(image)\nblock_idx = 0\nfor y in range(0, height, block_size):\n    for x in range(0, width, block_size):\n        block = reconstructed_blocks[block_idx]\n        reconstructed_image[y:y+block_size, x:x+block_size] = block\n        block_idx += 1\n# Display the reconstructed image using matplotlib\nplt.imshow(cv2.cvtColor(reconstructed_image, cv2.COLOR_BGR2RGB))\nplt.axis('off')  # Turn off axis labels\nplt.show()\n\n9/26/23, 7:10 PM\nUntitled0.ipynb - Colaboratory\nhttps://colab.research.google.com/drive/1sO9dZns8H-cbY8-WX6gGxybExNj-6I6n#scrollTo=N1ULFwmgqXi4&printMode=true\n3/4\nimport cv2\nimport numpy as np\nfrom scipy.fftpack import fft2, ifft2, dct, idct\n# Load the image\nimage = cv2.imread('photo1.jpeg')\n# Define the number of coefficients to retain\nnum_coefficients_to_retain = 50  # Adjust this number as needed\n# Convert the image to grayscale\ngray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n# Perform DFT\ndft_image = fft2(gray_image)\n# Perform DCT\ndct_image = dct(dct(gray_image, axis=0, norm='ortho'), axis=1, norm='ortho')\n# Retain only the specified number of coefficients for both transforms\ndft_image_reduced = np.copy(dft_image)\ndft_image_reduced[num_coefficients_to_retain:, num_coefficients_to_retain:] = 0\ndct_image_reduced = np.copy(dct_image)\ndct_image_reduced[num_coefficients_to_retain:, num_coefficients_to_retain:] = 0\n# Reconstruct the images from the reduced coefficients\nreconstructed_image_dft = np.abs(ifft2(dft_image_reduced)).astype(np.uint8)\nreconstructed_image_dct = idct(idct(dct_image_reduced, axis=0, norm='ortho'), axis=1, norm='ortho').astype(np.uint8)\n# Calculate the error between the original and reconstructed images\nerror_dft = np.mean(np.abs(gray_image - reconstructed_image_dft))\nerror_dct = np.mean(np.abs(gray_image - reconstructed_image_dct))\n# Display the original, DFT-reconstructed, and DCT-reconstructed images\nimport matplotlib.pyplot as plt\nplt.show()\nplt.figure(figsize=(10, 5))\nplt.subplot(131)\nplt.imshow(gray_image, cmap='gray')\nplt.title('Original Image')\nplt.axis('off')\nplt.subplot(132)\nplt.imshow(reconstructed_image_dft, cmap='gray')\nplt.title(f'DFT Reconstructed\\nError: {error_dft:.2f}')\nplt.axis('off')\nplt.subplot(133)\nplt.imshow(reconstructed_image_dct, cmap='gray')\nplt.title(f'DCT Reconstructed\\nError: {error_dct:.2f}')\nplt.axis('off')\nplt.tight_layout()\nplt.show()\n\n9/26/23, 7:10 PM\nUntitled0.ipynb - Colaboratory\nhttps://colab.research.google.com/drive/1sO9dZns8H-cbY8-WX6gGxybExNj-6I6n#scrollTo=N1ULFwmgqXi4&printMode=true\n4/4\n",
  "chunks": [
    "9/26/23, 7:10 PM Untitled0.ipynb - Colaboratory https://colab.research.google.com/drive/1sO9dZns8H-cbY8-WX6gGxybExNj-6I6n#scrollTo=N1ULFwmgqXi4&printMode=true 1/4 import cv2 import matplotlib.pyplot as plt # Load the image image = cv2.imread('photo1.jpeg') # Convert to grayscale gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY) # Display the grayscale image using matplotlib plt.imshow(gray_image, cmap='gray') plt.axis('off') # Turn off axis labels plt.show() import cv2 import numpy as np # Load the image image = cv2.imread('photo1.jpeg') # Define the size of the blocks (sub-images) block_size = 64 # Adjust this size according to your needs # Get the dimensions of the image height, width, _ = image.shape # Initialize a list to store the sub-images sub_images = [] # Iterate over the image in blocks for y in range(0, height, block_size): for x in range(0, width, block_size): # Extract the sub-image (block) sub_image = image[y:y+block_size, x:x+block_size] sub_images.append(sub_image) # Display or save the",
    "sub-images for i, sub_image in enumerate(sub_images): cv2.imwrite(f'sub_image_{i}.jpeg', sub_image) # Save each sub-image with a unique name # To display sub-images, you can use cv2.imshow here. # Note: This code saves each sub-image as separate files. You can adjust it as needed. import cv2 import numpy as np from scipy.fftpack import dct # Load the image and divide it into blocks (as shown in previous answers) image = cv2.imread('photo1.jpeg') block_size = 8 height, width, _ = image.shape sub_images = [] for y in range(0, height, block_size): 9/26/23, 7:10 PM Untitled0.ipynb - Colaboratory https://colab.research.google.com/drive/1sO9dZns8H-cbY8-WX6gGxybExNj-6I6n#scrollTo=N1ULFwmgqXi4&printMode=true 2/4 for x in range(0, width, block_size): sub_image = image[y:y+block_size, x:x+block_size] sub_images.append(sub_image) # Initialize a list to store DCT-transformed blocks dct_transformed_blocks = [] # Perform DCT on each sub-image (block) for sub_image in sub_images: # Convert the sub-image to grayscale",
    "gray_sub_image = cv2.cvtColor(sub_image, cv2.COLOR_BGR2GRAY) # Apply DCT dct_block = dct(dct(gray_sub_image, axis=0, norm='ortho'), axis=1, norm='ortho') dct_transformed_blocks.append(dct_block) # Define the quantization step size (adjust as needed) quantization_step = 10 # Initialize a list to store quantized blocks quantized_blocks = [] # Perform quantization on each DCT-transformed block for dct_block in dct_transformed_blocks: quantized_block = np.round(dct_block / quantization_step) quantized_blocks.append(quantized_block) import cv2 import numpy as np from scipy.fftpack import idct import matplotlib.pyplot as plt # Load the image and divide it into blocks (as shown in previous answers) image = cv2.imread('photo1.jpeg') block_size = 8 height, width, _ = image.shape sub_images = [] for y in range(0, height, block_size): for x in range(0, width, block_size): sub_image = image[y:y+block_size, x:x+block_size] sub_images.append(sub_image) # Initialize a list to store the reconstructed blocks",
    "reconstructed_blocks = [] # Perform inverse quantization and inverse DCT on each quantized block for quantized_block in quantized_blocks: # Inverse quantization reconstructed_dct_block = quantized_block * quantization_step # Inverse DCT reconstructed_gray_sub_image = idct(idct(reconstructed_dct_block, axis=0, norm='ortho'), axis=1, norm='ortho') # Create a 3-channel image (for color images) reconstructed_sub_image = cv2.cvtColor(reconstructed_gray_sub_image.astype(np.uint8), cv2.COLOR_GRAY2BGR) reconstructed_blocks.append(reconstructed_sub_image) # Reconstruct the image by arranging the blocks reconstructed_image = np.zeros_like(image) block_idx = 0 for y in range(0, height, block_size): for x in range(0, width, block_size): block = reconstructed_blocks[block_idx] reconstructed_image[y:y+block_size, x:x+block_size] = block block_idx += 1 # Display the reconstructed image using matplotlib plt.imshow(cv2.cvtColor(reconstructed_image, cv2.COLOR_BGR2RGB)) plt.axis('off') # Turn off axis labels plt.show()",
    "9/26/23, 7:10 PM Untitled0.ipynb - Colaboratory https://colab.research.google.com/drive/1sO9dZns8H-cbY8-WX6gGxybExNj-6I6n#scrollTo=N1ULFwmgqXi4&printMode=true 3/4 import cv2 import numpy as np from scipy.fftpack import fft2, ifft2, dct, idct # Load the image image = cv2.imread('photo1.jpeg') # Define the number of coefficients to retain num_coefficients_to_retain = 50 # Adjust this number as needed # Convert the image to grayscale gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY) # Perform DFT dft_image = fft2(gray_image) # Perform DCT dct_image = dct(dct(gray_image, axis=0, norm='ortho'), axis=1, norm='ortho') # Retain only the specified number of coefficients for both transforms dft_image_reduced = np.copy(dft_image) dft_image_reduced[num_coefficients_to_retain:, num_coefficients_to_retain:] = 0 dct_image_reduced = np.copy(dct_image) dct_image_reduced[num_coefficients_to_retain:, num_coefficients_to_retain:] = 0 # Reconstruct the images from the reduced coefficients reconstructed_image_dft =",
    "np.abs(ifft2(dft_image_reduced)).astype(np.uint8) reconstructed_image_dct = idct(idct(dct_image_reduced, axis=0, norm='ortho'), axis=1, norm='ortho').astype(np.uint8) # Calculate the error between the original and reconstructed images error_dft = np.mean(np.abs(gray_image - reconstructed_image_dft)) error_dct = np.mean(np.abs(gray_image - reconstructed_image_dct)) # Display the original, DFT-reconstructed, and DCT-reconstructed images import matplotlib.pyplot as plt plt.show() plt.figure(figsize=(10, 5)) plt.subplot(131) plt.imshow(gray_image, cmap='gray') plt.title('Original Image') plt.axis('off') plt.subplot(132) plt.imshow(reconstructed_image_dft, cmap='gray') plt.title(f'DFT Reconstructed\\nError: {error_dft:.2f}') plt.axis('off') plt.subplot(133) plt.imshow(reconstructed_image_dct, cmap='gray') plt.title(f'DCT Reconstructed\\nError: {error_dct:.2f}') plt.axis('off') plt.tight_layout() plt.show() 9/26/23, 7:10 PM Untitled0.ipynb - Colaboratory",
    "https://colab.research.google.com/drive/1sO9dZns8H-cbY8-WX6gGxybExNj-6I6n#scrollTo=N1ULFwmgqXi4&printMode=true 4/4"
  ],
  "metadata": {
    "filename": "abhishek udeniyan transform report.pdf",
    "processed_date": "2025-06-11T18:53:49.562637",
    "num_chunks": 7,
    "source_type": "file",
    "file_size": 648400
  }
}